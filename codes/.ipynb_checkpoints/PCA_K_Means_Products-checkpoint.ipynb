{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Clustering using PCA and K Means for Products\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction import text \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data\n",
    "df = pd.read_csv('../raw/meals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect data\n",
    "# pd.options.display.max_columns = None\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ini_rows = df.shape[0]\n",
    "ini_columns=df.shape[1]\n",
    "print('We have {} records of transactions for {} unique items.'.format(ini_rows,df.id.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_features = df[['ingredients','temperature','macros','price','category','name','id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_features.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile ingredients as corpus\n",
    "texts = pd.DataFrame(menu_features.ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect corpus\n",
    "texts.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removes punctuation\n",
    "texts['clean_text'] = texts.ingredients.map(lambda x : ''.join(k for k in str(x) if k not in string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_stopwords = ['001', '003', '01', '05', '07', '11', '13', '18', '6070', '74']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec_full_list = CountVectorizer(stop_words = text.ENGLISH_STOP_WORDS.union(add_stopwords),max_features=500)\n",
    "cvec_full_list.fit(texts.clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = pd.DataFrame(cvec_full_list.transform(texts.clean_text).todense(),columns=cvec_full_list.get_feature_names())\n",
    "word_count = bow.sum(axis=0)\n",
    "\n",
    "print(\"Most common ingredients:\")\n",
    "word_count.sort_values(ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cvec_full_list.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ingre_dum = np.zeros((menu_features.id.nunique(),500)) #row=items, col=ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.DataFrame(np.zeros((menu_features.id.nunique(),500)),index = menu_features.id.unique(), columns = cvec_full_list.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_features['clean_ingre'] = menu_features.ingredients.map(lambda x : ''.join(k for k in str(x) if k not in string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in menu_features.id.unique():\n",
    "    cvec = CountVectorizer(stop_words = text.ENGLISH_STOP_WORDS.union(add_stopwords))\n",
    "    cvec.fit(menu_features.loc[menu_features.id==item,'ingredients'])\n",
    "    for word in cvec.get_feature_names():\n",
    "        if word in cvec_full_list.get_feature_names():\n",
    "            matrix.loc[item,word] = 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.get_dummies(menu_features.temperature, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix['price'] = 0\n",
    "for i in matrix.index:\n",
    "    matrix.loc[i,'price'] = menu_features.loc[menu_features.id==i,'price'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Check possible values\n",
    "menu_features.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are repeated categories such as 'main' and 'Main Course' which can be consolidated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Consolidating similiar categories\n",
    "def consolidate_cat(x):\n",
    "    if x == 'Main Course':\n",
    "        return 'main'\n",
    "    elif x == 'Appetiser':\n",
    "        return 'side'\n",
    "    elif x == 'Dessert':\n",
    "        return 'dessert'\n",
    "    elif x == 'partnership':\n",
    "        return 'off_menu'\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "menu_features.category = menu_features.category.apply(lambda x : consolidate_cat(x))\n",
    "\n",
    "#Print new categories\n",
    "menu_features.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = pd.get_dummies(menu_features.category, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = menu_features.macros.str.split(', ', n=5, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_values_into_name_and_val(col):\n",
    "    new[str(col)+'_macros_name'] = new[col].str.split(':', n=2, expand=True)[0].fillna('None').map(lambda x: x.lower())\n",
    "    new[str(col)+'_macros_val'] = new[col].str.split(':', n=2, expand=True)[1]\n",
    "    print(new[str(col)+'_macros_name'].unique())\n",
    "\n",
    "for col in new:\n",
    "    split_values_into_name_and_val(col)\n",
    "\n",
    "new.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new['calories'] = 0\n",
    "new['fat'] = 0\n",
    "new['protein'] = 0\n",
    "new['carb'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new.loc[new['0_macros_name'] == 'calories', 'calories'] = new.loc[new['0_macros_name'] == 'calories', '0_macros_val']\n",
    "new.loc[new['0_macros_name'] == ' calories', 'calories'] = new.loc[new['0_macros_name'] == ' calories', '0_macros_val']\n",
    "\n",
    "new.loc[new['1_macros_name'] == 'calories', 'calories'] = new.loc[new['1_macros_name'] == 'calories', '1_macros_val']\n",
    "new.loc[new['1_macros_name'] == 'fat', 'fat'] = new.loc[new['1_macros_name'] == 'fat', '1_macros_val']\n",
    "new.loc[new['1_macros_name'] == 'protein', 'protein'] = new.loc[new['1_macros_name'] == 'protein', '1_macros_val']\n",
    "new.loc[new['1_macros_name'] == 'carbs', 'carb'] = new.loc[new['1_macros_name'] == 'carbs', '1_macros_val']\n",
    "\n",
    "new.loc[new['2_macros_name'] == 'fat', 'fat'] = new.loc[new['2_macros_name'] == 'fat', '2_macros_val']\n",
    "new.loc[new['2_macros_name'] == 'protein', 'protein'] = new.loc[new['2_macros_name'] == 'protein', '2_macros_val']\n",
    "new.loc[new['2_macros_name'] == 'carb', 'carb'] = new.loc[new['2_macros_name'] == 'carb', '2_macros_val']\n",
    "\n",
    "new.loc[new['3_macros_name'] == ' fat', 'fat'] = new.loc[new['3_macros_name'] == ' fat', '3_macros_val']\n",
    "new.loc[new['3_macros_name'] == 'protein', 'protein'] = new.loc[new['3_macros_name'] == 'protein', '3_macros_val']\n",
    "new.loc[new['3_macros_name'] == 'carb', 'carb'] = new.loc[new['3_macros_name'] == 'carb', '3_macros_val']\n",
    "\n",
    "new.loc[new['4_macros_name'] == 'protein', 'protein'] = new.loc[new['4_macros_name'] == 'protein', '4_macros_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove g\n",
    "cols = ['fat','protein','carb']\n",
    "for i in cols:\n",
    "    new[str(i)] = new[str(i)].apply(lambda x: str(x).split('g')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['calories', 'fat','protein','carb']:\n",
    "    new[i] = new[i].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_macros = new[['calories', 'fat','protein','carb']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([menu_features,df_cat,df_macros,df_temp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['id','drink', 'favorite', 'fresh', 'guilt-free','highlight', 'local', 'main', \n",
    "   'off_menu', 'regular', 'side', 'calories','fat', 'protein', 'carb', 'room', 'warm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = matrix.merge(df,how='left',left_on=matrix.index, right_on='id', suffixes=('_mat','_features')).drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "Xs = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=20)\n",
    "principalComponents = pca.fit_transform(Xs)\n",
    "\n",
    "# Plot the explained variances\n",
    "features = range(pca.n_components_)\n",
    "plt.bar(features, pca.explained_variance_ratio_)\n",
    "plt.xlabel('PCA features')\n",
    "plt.ylabel('variance %')\n",
    "plt.xticks(features)\n",
    "\n",
    "# Save components to a DataFrame\n",
    "PCA_components = pd.DataFrame(principalComponents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = range(1, 10)\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "for k in ks:\n",
    "    # Create a KMeans instance with k clusters: model\n",
    "    knn_model = KMeans(n_clusters=k)\n",
    "    \n",
    "    # Fit model to samples\n",
    "    knn_model.fit(PCA_components.iloc[:,:9])\n",
    "    \n",
    "    # Append the inertia to the list of inertias\n",
    "    inertias.append(knn_model.inertia_)\n",
    "\n",
    "    \n",
    "plt.plot(ks, inertias, '-o', color='black')\n",
    "plt.xlabel('number of clusters, k')\n",
    "plt.ylabel('inertia')\n",
    "plt.xticks(ks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(PCA_components[3], PCA_components[2], alpha=.05, color='brown')\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=2)\n",
    "model.fit(PCA_components.iloc[:,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['cluster'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.cluster.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_score(Xs, pred, metric='euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
